

一期资源池虚机搭建容器 Swarm 集群，跨节点 Overlay 网络（Vxlan）方案不通，排查过程如下：

> 1- 本地环境 Swarm 集群，自建 Overlay 网络，跨节点容器间正常互通；
> 2- 资源池虚机（不同计算节点）Swarm 集群，自建 Overlay 网络，跨虚机容器间不通；
> 3- 资源池虚机（同一计算节点）Swarm 集群，自建 Overlay 网络，跨虚机容器间正常互通；
> 4- 容器互联测试，其所在虚机抓包 -> 宿主机抓包 -> 架顶交换机（CE6855）抓包-异常
> 5- 交换机更改端口模式，提供对 Vxlan 包接入支持，问题解决

问题定位：容器发出包（Vxlan），经过虚机到宿主机，进入架顶交换机后没有流出，
咨询华为工程师提供该交换机对虚机内容器 Overlay 网络支持方案。



## || 多场景抓包分析

### 1- 本地跨物理机 Swarm 集群，跨节点容器通信 [正常]

集群信息
 
 物理机 | 容器
------------- | ------------- 
 Swarm01 - 10.50.50.149 | ngtest.3 - 10.10.10.12 
 Swarm03 - 10.50.50.151 | ngtest.4 - 10.10.10.8

集群 Overlay 网络：

```bash
# docker network inspect myolnet
...
    {
        "Name": "myolnet",
        "Id": "6x6r0bser8twa3qaylqvwv3sz",
        "Scope": "swarm",
        "Driver": "overlay",
        "EnableIPv6": false,
        "IPAM": {
            "Driver": "default",
            "Options": null,
            "Config": [
                {
                    "Subnet": "10.10.10.0/24",
                    "Gateway": "10.10.10.1"
...
```

从 Swarm03 节点上 ngtest.4 容器对 Swarm01 节点上 ngtest.3 容器做联通测试

```bash
# docker exec ngtest.4.ckqgty4hxvffoh7gurgh4g1q7 ping ngtest.3.06186x1njdfvt5szgee261vw5
PING ngtest.3.06186x1njdfvt5szgee261vw5 (10.10.10.12): 56 data bytes
64 bytes from 10.10.10.12: icmp_seq=0 ttl=64 time=0.849 ms
64 bytes from 10.10.10.12: icmp_seq=1 ttl=64 time=0.855 ms
64 bytes from 10.10.10.12: icmp_seq=2 ttl=64 time=0.604 ms
...
```

两侧分别抓包

Swarm01

```bash
# tcpdump -i ens33 host swarm01 and swarm03 -w Swarm3toSwarm1onS1.pcap
```

Swarm03

```bash
# tcpdump -i ens33 host swarm03 and swarm01 -w Swarm3toSwarm1onS3.pcap
```

查看结果

Swarm01 端

![Swarm3toSwarm1onS1](http://ov30w4cpi.bkt.clouddn.com/Swarm3toSwarm1onS1.png)

Swarm03 端

![Swarm3toSwarm1onS1](http://ov30w4cpi.bkt.clouddn.com/Swarm3toSwarm1onS3.png)


端口访问测试

```bash
# docker exec -it  ngtest.4.ckqgty4hxvffoh7gurgh4g1q7 wget ngtest.3.06186x1njdfvt5szgee261vw5
--2017-11-05 07:31:45--  http://ngtest.3.06186x1njdfvt5szgee261vw5/
Resolving ngtest.3.06186x1njdfvt5szgee261vw5 (ngtest.3.06186x1njdfvt5szgee261vw5)... 10.10.10.12
Connecting to ngtest.3.06186x1njdfvt5szgee261vw5 (ngtest.3.06186x1njdfvt5szgee261vw5)|10.10.10.12|:80... connected.
HTTP request sent, awaiting response... 200 OK
Length: 612 [text/html]
Saving to: 'index.html'

index.html                  100%[========================================>]     612  --.-KB/s    in 0s      

2017-11-05 07:31:45 (36.1 MB/s) - 'index.html' saved [612/612]

```

两侧分别抓包（同上）

查看结果

Swarm01 端

![Swarm3toSwarm1onS1wget](http://ov30w4cpi.bkt.clouddn.com/Swarm3toSwarm1onS1wget.png)

Swarm03 端

![Swarm3toSwarm1onS1wget](http://ov30w4cpi.bkt.clouddn.com/Swarm3toSwarm1onS3wget.png)

**结论：Swarm 集群的 Overlay 网络可以实现跨节点的容器间互通**


### 2- 资源池环境虚机跨计算节点

集群信息

 计算节点 | 虚拟机 | 容器
------------- | ------------- | -------------
 compute-h10-10.domain.tld | lzy02 - 192.101.0.18 | ngmigu.3 - 10.20.20.4 
 compute-h04-3.domain.tld | lzy03 - 192.101.0.19 | ngmigu.1 - 10.20.20.6

集群 Overlay 网络

```bash
# docker network inspect migunet
...
    {
        "Name": "migunet",
        "Id": "6njyo6ctzjobc0sg3o32sttu0",
        "Scope": "swarm",
        "Driver": "overlay",
        "EnableIPv6": false,
        "IPAM": {
            "Driver": "default",
            "Options": null,
            "Config": [
                {
                    "Subnet": "10.20.20.0/24",
                    "Gateway": "10.20.20.1"
...
```

容器分布

```bash
# docker service ps ngmigu
ID                         NAME      IMAGE  NODE   DESIRED STATE  CURRENT STATE           ERROR
bzgupynir43zwg1qy4deu3q7g  ngmigu.1  nginx  lzy-3  Running        Running 11 minutes ago  
134hva4h0zedar2yuau597t61  ngmigu.2  nginx  lzy-3  Running        Running 11 minutes ago  
ahuxyhjtqzt9ccum86cnezm18  ngmigu.3  nginx  lzy-2  Running        Running 12 minutes ago  
d7yz0pw7989xmzzeatdyt0a1d  ngmigu.4  nginx  lzy-2  Running        Running 12 minutes ago  
```

从 lzy03 节点上 ngmigu.1 容器对 lzy02 节点上 ngmigu.3 容器做联通测试

```bash
# docker exec ngmigu.1.a6hqpwpr9sycuc6y8h3cpuajf ping ngmigu.3.c1098rxxodhx38iyp4pz8ufg1
PING ngmigu.3.c1098rxxodhx38iyp4pz8ufg1 (10.20.20.4): 56 data bytes

```

两侧分别抓包

Lzy02

```bash
# tcpdump -i eth0 host lzy02 and lzy03 -w Lzy03toLzy02onL2.pcap
```

Lzy03

```bash
# tcpdump -i eth0 host lzy03 and lzy02 -w Lzy03toLzy02onL3.pcap
```

查看结果

Lzy02 端

![Lzy03toLzy02onL2](http://ov30w4cpi.bkt.clouddn.com/Lzy03toLzy02onL2.png)

Lzy03 端

![Lzy03toLzy02onL3](http://ov30w4cpi.bkt.clouddn.com/Lzy03toLzy02onL3.png)

**从虚机 Lzy03 发出的包没有应答，在 Lzy02 端则没收到包，继续在宿主机上抓包**

Compute-h10-10

```bash
# ovs-tcpdump -i bond2 -w Ch04-3toCh10-10onC10-10.pcap
```

Compute-h04-3

```bash
# ovs-tcpdump -i bond2 -w Ch04-3toCh10-10onC04-3.pcap
```

查看结果

Compute-h10-10 端

![Ch04-3toCh10-10onC10-10](http://ov30w4cpi.bkt.clouddn.com/Ch04-3toCh10-10onC10-10.png)

Compute-h04-3 端

![Ch04-3toCh10-10onC04-3](http://ov30w4cpi.bkt.clouddn.com/Ch04-3toCh10-10onC04-3.png)

**物理机上已发出包，而对端计算节点没有收到，问题可能出在架顶交换机（CE6855）**

对交换机入口、出口抓包，结果如下

入口

![tor入口](http://ov30w4cpi.bkt.clouddn.com/torin.png)

出口

![tor出口](http://ov30w4cpi.bkt.clouddn.com/torout.png)

**结论：容器发出的 Vxlan 包进入架顶交换机后没有流出，需架顶交换机对携带 Vxlan 报文的网络包提供转发支持。**


## || 架顶交换机配置

型号：CE6855

缺省情况下，未指定端口模式为 Vxlan 网络接入端口，即携带 Vxlan 报文目的 UDP 端口号（缺省值为 4789）的普通IP报文不能接入 Vxlan 网络。

**命令**
```bash
port nvo3 mode access
```

该命令用来指定端口模式为 Vxlan 网络接入端口，从而允许携带 Vxlan 报文目的 UDP 端口号（缺省值为 4789）的普通IP报文接入 Vxlan 网络。

生效后测试

![互通成功](http://ov30w4cpi.bkt.clouddn.com/hutongchenggong.png)

后期资源池环境中需要跑容器云的计算节点，其架顶交换机接入端口需要预更改模式

## || Swarm 集群 Overlay 网络

Docker 内置的 Overlay 网络是采用 IETF 标准的 Vxlan 方式

### 1- Swarm 介绍

https://docs.docker.com/v1.12/swarm/overview/

### 2- Swarm 集群 Overlay 网络方案介绍

https://docs.docker.com/engine/userguide/networking/#overlay-networks-in-swarm-mode
http://blog.nigelpoulton.com/demystifying-docker-overlay-networking/

**注意事项**

在 Swarm 集群中，**4789** 和 **7946** 两个端口需要放开

Port 4789 UDP for the container overlay network.
Port 7946 TCP/UDP for container network discovery.


## || Swarm 集群搭建及 Overlay 网络配置

### 0- 升级内核

官网建议对 CentOS7 内核做升级，默认的 3.10 版本会有网段重复的可能

> On some older kernels, including kernel 3.10, automatically assigned addresses may overlap with another subnet in your infrastructure. 

升级到 4.13 版本

```bash
# rpm --import https://www.elrepo.org/RPM-GPG-KEY-elrepo.org

# rpm -Uvh http://www.elrepo.org/elrepo-release-7.0-2.el7.elrepo.noarch.rpm

# yum --enablerepo=elrepo-kernel install  kernel-ml-devel kernel-ml -y

# grub2-set-default 0

# reboot

# uname -r
4.13.11-1.el7.elrepo.x86_64
```

### 1- 安装 docker 

```bash
# yum install docker -y

# systemctl enable docker && systemctl start docker
```

### 2- 创建 Swarm 集群

```bash
# docker swarm init --advertise-addr 10.50.50.148
Swarm initialized: current node (7od1svfv9vbq44smjx5ye6r9j) is now a manager.

To add a worker to this swarm, run the following command:

    docker swarm join \
    --token SWMTKN-1-1hkr00feszghf3y5v35phbr5dvur4qb664byl1lv58d23h207p-2cbec797yhegoamyhgqrcmips \
    10.50.50.148:2377

To add a manager to this swarm, run 'docker swarm join-token manager' and follow the instructions. 
```



### 3- 创建 Overlay 网络

```bash
# docker network create -d overlay --subnet 10.10.10.0/24 --gateway 10.10.10.1 migunet
```






